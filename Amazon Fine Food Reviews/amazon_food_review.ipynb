{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Farahi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the Objective is to find wether a review is positive or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sql.connect('data/database.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "    select * \n",
    "    from Reviews\n",
    "    where Score != 3\n",
    "    \"\"\",\n",
    "    con\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(x) -> str:\n",
    "    if x < 3:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Positive\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Score = data[\"Score\"].map(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "0                     1                       1  Positive  1303862400   \n",
       "1                     0                       0  Negative  1346976000   \n",
       "2                     1                       1  Positive  1219017600   \n",
       "3                     3                       3  Negative  1307923200   \n",
       "4                     0                       0  Positive  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning: Dedublication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "    select *\n",
    "    from Reviews\n",
    "    where Score != 3 and UserId = \"AR5J8UI46CURR\"\n",
    "    order by ProductId\n",
    "    \"\"\",\n",
    "    con\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78445</td>\n",
       "      <td>B000HDL1RQ</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138317</td>\n",
       "      <td>B000HDOPYC</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138277</td>\n",
       "      <td>B000HDOPYM</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73791</td>\n",
       "      <td>B000HDOPZG</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155049</td>\n",
       "      <td>B000PAQ75C</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   ProductId         UserId      ProfileName  HelpfulnessNumerator  \\\n",
       "0   78445  B000HDL1RQ  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "1  138317  B000HDOPYC  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "2  138277  B000HDOPYM  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "3   73791  B000HDOPZG  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "4  155049  B000PAQ75C  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time  \\\n",
       "0                       2      5  1199577600   \n",
       "1                       2      5  1199577600   \n",
       "2                       2      5  1199577600   \n",
       "3                       2      5  1199577600   \n",
       "4                       2      5  1199577600   \n",
       "\n",
       "                             Summary  \\\n",
       "0  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "1  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "2  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "3  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "4  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "\n",
       "                                                Text  \n",
       "0  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "1  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "2  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "3  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "4  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525814, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data = data.sort_values(\"ProductId\", axis=0, ascending=True)\n",
    "sorted_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = sorted_data.drop_duplicates(subset=[\"UserId\", \"ProfileName\", \"Text\", \"Time\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364173, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.25890143662969"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking how much data we left with it\n",
    "(final['Id'].size*1.0)/(data['Id'].size*1.0)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64422</td>\n",
       "      <td>B000MIDROQ</td>\n",
       "      <td>A161DK06JJMCYF</td>\n",
       "      <td>J. E. Stephens \"Jeanne\"</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1224892800</td>\n",
       "      <td>Bought This for My Son at College</td>\n",
       "      <td>My son loves spaghetti so I didn't hesitate or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44737</td>\n",
       "      <td>B001EQ55RW</td>\n",
       "      <td>A2V0I904FH7ABY</td>\n",
       "      <td>Ram</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1212883200</td>\n",
       "      <td>Pure cocoa taste with crunchy almonds inside</td>\n",
       "      <td>It was almost a 'love at first bite' - the per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id   ProductId          UserId              ProfileName  \\\n",
       "0  64422  B000MIDROQ  A161DK06JJMCYF  J. E. Stephens \"Jeanne\"   \n",
       "1  44737  B001EQ55RW  A2V0I904FH7ABY                      Ram   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     3                       1      5  1224892800   \n",
       "1                     3                       2      4  1212883200   \n",
       "\n",
       "                                        Summary  \\\n",
       "0             Bought This for My Son at College   \n",
       "1  Pure cocoa taste with crunchy almonds inside   \n",
       "\n",
       "                                                Text  \n",
       "0  My son loves spaghetti so I didn't hesitate or...  \n",
       "1  It was almost a 'love at first bite' - the per...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "    select *\n",
    "    from Reviews\n",
    "    where Score != 3 and Id = 44737 or Id = 64422\n",
    "    order by ProductId\n",
    "    \"\"\",\n",
    "    con\n",
    ")\n",
    "display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    0.843178\n",
       "Negative    0.156822\n",
       "Name: Score, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[\"Score\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?', \n",
    "]\n",
    "\n",
    "vectorize = CountVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = vectorize.fit_transform(corpus)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
       "       'this'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.toarray())\n",
    "vectorize.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and this', 'document is', 'first document', 'is the', 'is this',\n",
       "       'second document', 'the first', 'the second', 'the third',\n",
       "       'third one', 'this document', 'this is', 'this the'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "X2 = vectorizer2.fit_transform(corpus)\n",
    "vectorizer2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 0 0 1 0 0 0 0 1 0]\n",
      " [0 1 0 1 0 1 0 1 0 0 1 0 0]\n",
      " [1 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      " [0 0 1 0 1 0 1 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "final_count = count_vec.fit_transform(final.Text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 115281)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing: Stemming, stop-word removal and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "I set aside at least an hour each day to read to my son (3 y/o). At this point, I consider myself a connoisseur of children's books and this is one of the best. Santa Clause put this under the tree. Since then, we've read it perpetually and he loves it.<br /><br />First, this book taught him the months of the year.<br /><br />Second, it's a pleasure to read. Well suited to 1.5 y/o old to 4+.<br /><br />Very few children's books are worth owning. Most should be borrowed from the library. This book, however, deserves a permanent spot on your shelf. Sendak's best.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "#  www.pymotw.com/2/re/\n",
    "i = 0\n",
    "for sent in final.Text.values:\n",
    "    if(len(re.findall('<.*?>', sent))):\n",
    "        print(i)\n",
    "        print(sent)\n",
    "        break\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "sno = nltk.stem.SnowballStemmer(\"english\")\n",
    "\n",
    "def cleanHtml(sent):\n",
    "    clear = re.compile('<.*?>')\n",
    "    clean_text = re.sub(clear, ' ', sent)\n",
    "    return clean_text\n",
    "\n",
    "def cleanPunc(sent):\n",
    "    clean = re.sub(r'[?|!|\\'|\"|#]', r'', sent)\n",
    "    clean = re.sub(r'[.|,|)|(|\\|/]', r'', sent)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the', 'or', 'you', 'further', 'myself', 've', \"isn't\", \"mustn't\", 'those', 'are', \"weren't\", 'that', 'hadn', \"couldn't\", 't', 'should', 'of', 'few', 'what', 'wasn', 'between', 'before', 'hasn', 'this', 'below', 'than', 'yours', 'wouldn', 'a', 'once', \"doesn't\", 'isn', 'they', 'himself', 'both', 'then', \"aren't\", 'we', 'am', 'while', 'shan', 'our', 'there', 'been', 'each', 'until', 's', 'your', 'about', 'why', 'can', \"you'll\", 'o', 'them', 'out', 'by', \"wasn't\", 'itself', 'll', 'and', 'm', 'won', 'themselves', 'for', 'me', 'it', 'him', 'how', 'having', 'mightn', 'my', 'does', 'just', 'weren', 'has', \"you'd\", 'under', 'no', 'aren', 'ain', 'on', 'all', 'who', 'ma', 'in', 'y', 'his', 'did', 'most', 'only', 'these', 'i', 'be', \"she's\", 'hers', \"hasn't\", \"mightn't\", \"needn't\", 'from', \"should've\", 'yourselves', 'd', 'mustn', 'some', 'too', 'couldn', 'through', \"shan't\", 'was', 'which', 'when', 'where', 'doing', 'because', \"haven't\", 'again', 'whom', \"didn't\", 'were', 'ours', 'above', 'he', 'off', 'against', \"you've\", 'didn', 'an', 'as', 'don', 'herself', 'but', 'here', 'doesn', 're', 'into', 'have', 'very', \"that'll\", 'theirs', 'more', 'haven', 'now', 'her', 'with', \"hadn't\", 'needn', 'at', 'she', \"you're\", 'will', 'up', 'being', 'do', 'any', \"don't\", \"it's\", 'to', 'own', 'not', 'if', 'their', 'after', \"wouldn't\", 'same', 'yourself', 'over', 'such', 'is', 'nor', 'other', 'so', 'down', 'ourselves', \"shouldn't\", 'its', 'during', \"won't\", 'had', 'shouldn'}\n",
      "_________________________________________________________________\n",
      "tasti\n"
     ]
    }
   ],
   "source": [
    "print(stop)\n",
    "print(\"_________________________________________________________________\")\n",
    "print(sno.stem(\"tasty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "str1 = ' '\n",
    "final_string = []\n",
    "all_pos_words = []\n",
    "all_neg_words = []\n",
    "s=''\n",
    "\n",
    "for sent in final.Text.values:\n",
    "    filterd_sent = []\n",
    "    sent = cleanHtml(sent)\n",
    "    for w in sent.split():\n",
    "        for clean_word in cleanPunc(w).split():\n",
    "            if((clean_word.isalpha()) & (len(clean_word) > 2)):\n",
    "                if(clean_word.islower() not in stop):\n",
    "                    s = (sno.stem(clean_word.lower())).encode('utf8')\n",
    "                    filterd_sent.append(s)\n",
    "                    if(final.Score.values)[i] == 'Positive':\n",
    "                        all_pos_words.append(s)\n",
    "                    if(final.Score.values)[i] == 'Negative':\n",
    "                        all_neg_words.append(s)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "    str1 = b\" \".join(filterd_sent)\n",
    "    final_string.append(str1)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "final[\"CleandText\"] = final_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sql.connect(\"final.sqlite\")\n",
    "c = conn.cursor()\n",
    "conn.text_factory = str\n",
    "final.to_sql('Reviews', conn, schema=None, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-Grams and n-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Postive words [(b'the', 940048), (b'and', 694890), (b'this', 354609), (b'for', 296172), (b'that', 212057), (b'have', 193685), (b'with', 192845), (b'you', 180798), (b'but', 177024), (b'are', 165544), (b'was', 146722), (b'not', 145518), (b'they', 141255), (b'like', 138531), (b'tast', 126159), (b'these', 116660), (b'good', 107583), (b'love', 106314), (b'flavor', 106287), (b'them', 104833)]\n",
      "common negative words [(b'the', 221082), (b'and', 121243), (b'this', 77923), (b'not', 53823), (b'was', 51742), (b'that', 50651), (b'for', 49403), (b'but', 42524), (b'have', 35900), (b'tast', 33876), (b'with', 33520), (b'like', 32136), (b'they', 31585), (b'you', 30445), (b'product', 27341), (b'are', 26609), (b'these', 20647), (b'one', 20203), (b'had', 19260), (b'from', 19242)]\n"
     ]
    }
   ],
   "source": [
    "freq_dist_positive = nltk.FreqDist(all_pos_words)\n",
    "freq_dist_negative = nltk.FreqDist(all_neg_words)\n",
    "print(\"Common Postive words\", freq_dist_positive.most_common(20))\n",
    "print(\"common negative words\", freq_dist_negative.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: from the above it can be seen that the most common positive and the negative words\\\n",
    "overlabs for eg. 'like' could be used as 'not like' etc..\\\n",
    "so, it is good idea to consider pairs of consequent words (bi-grams) or q sequence of n consecutive words (n-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(1,2))\n",
    "final_bigram_counts = count_vect.fit_transform(final.Text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 2910192)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_bigram_counts.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "final_tf_idf = tf_idf_vect.fit_transform(final.Text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 2910192)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tf_idf.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Farahi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2910192"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuers = tf_idf_vect.get_feature_names()\n",
    "len(featuers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ales until',\n",
       " 'ales ve',\n",
       " 'ales would',\n",
       " 'ales you',\n",
       " 'alessandra',\n",
       " 'alessandra ambrosia',\n",
       " 'alessi',\n",
       " 'alessi added',\n",
       " 'alessi also',\n",
       " 'alessi and',\n",
       " 'alessi are',\n",
       " 'alessi at',\n",
       " 'alessi brand',\n",
       " 'alessi breadsticks',\n",
       " 'alessi caffe',\n",
       " 'alessi cento',\n",
       " 'alessi chicken',\n",
       " 'alessi coarse',\n",
       " 'alessi coffees',\n",
       " 'alessi decaf',\n",
       " 'alessi decafeinated',\n",
       " 'alessi decaffenated',\n",
       " 'alessi dipping',\n",
       " 'alessi disposable',\n",
       " 'alessi espresso',\n",
       " 'alessi fig',\n",
       " 'alessi fine',\n",
       " 'alessi for',\n",
       " 'alessi from',\n",
       " 'alessi garlic',\n",
       " 'alessi grinder',\n",
       " 'alessi has',\n",
       " 'alessi imported',\n",
       " 'alessi in',\n",
       " 'alessi is',\n",
       " 'alessi lavazza',\n",
       " 'alessi made',\n",
       " 'alessi makes',\n",
       " 'alessi mushroom',\n",
       " 'alessi or',\n",
       " 'alessi other',\n",
       " 'alessi packet',\n",
       " 'alessi products',\n",
       " 'alessi richard',\n",
       " 'alessi rosemary',\n",
       " 'alessi salt',\n",
       " 'alessi savoiadi',\n",
       " 'alessi seems',\n",
       " 'alessi sell',\n",
       " 'alessi sesame',\n",
       " 'alessi soup',\n",
       " 'alessi soups',\n",
       " 'alessi split',\n",
       " 'alessi star',\n",
       " 'alessi thin',\n",
       " 'alessi vigo',\n",
       " 'alessi wasn',\n",
       " 'alessi went',\n",
       " 'alessi white',\n",
       " 'alessi whole',\n",
       " 'alessi zuppa',\n",
       " 'alete',\n",
       " 'alete and',\n",
       " 'aleutian',\n",
       " 'aleutian chain',\n",
       " 'aleve',\n",
       " 'aleve but',\n",
       " 'aleve during',\n",
       " 'aleve every',\n",
       " 'aleve everyday',\n",
       " 'aleve for',\n",
       " 'aleve this',\n",
       " 'aleve to',\n",
       " 'aleviate',\n",
       " 'aleviate knee',\n",
       " 'aleviate the',\n",
       " 'aleviated',\n",
       " 'aleviated my',\n",
       " 'alevitated',\n",
       " 'alevitated those',\n",
       " 'alex',\n",
       " 'alex 1y',\n",
       " 'alex apartment',\n",
       " 'alex baldwin',\n",
       " 'alex br',\n",
       " 'alex character',\n",
       " 'alex continues',\n",
       " 'alex cord',\n",
       " 'alex duetto',\n",
       " 'alex for',\n",
       " 'alex hah',\n",
       " 'alex his',\n",
       " 'alex medicine',\n",
       " 'alex months',\n",
       " 'alex my',\n",
       " 'alex ovechkin',\n",
       " 'alex rip',\n",
       " 'alex she',\n",
       " 'alex takes',\n",
       " 'alex theater',\n",
       " 'alex trebek',\n",
       " 'alex vizsla',\n",
       " 'alex who',\n",
       " 'alex you',\n",
       " 'alexander',\n",
       " 'alexander br',\n",
       " 'alexander diaz',\n",
       " 'alexander dumas',\n",
       " 'alexander mallas',\n",
       " 'alexander mccall',\n",
       " 'alexander mckeag',\n",
       " 'alexander pope',\n",
       " 'alexander valley',\n",
       " 'alexander ve',\n",
       " 'alexandra',\n",
       " 'alexandra adores',\n",
       " 'alexandra is',\n",
       " 'alexandre',\n",
       " 'alexandre le',\n",
       " 'alexandria',\n",
       " 'alexandria va',\n",
       " 'alexandria virginia',\n",
       " 'alexi',\n",
       " 'alexi eats',\n",
       " 'alexi goes',\n",
       " 'alexia',\n",
       " 'alexia onion',\n",
       " 'alexian',\n",
       " 'alexian pate',\n",
       " 'alexis',\n",
       " 'alexis br',\n",
       " 'alf',\n",
       " 'alf and',\n",
       " 'alf brand',\n",
       " 'alf it',\n",
       " 'alfa',\n",
       " 'alfa alfa',\n",
       " 'alfa brand',\n",
       " 'alfa has',\n",
       " 'alfa in',\n",
       " 'alfa is',\n",
       " 'alfa romeo',\n",
       " 'alfafa',\n",
       " 'alfafa fed',\n",
       " 'alfajores',\n",
       " 'alfajores american',\n",
       " 'alfajores are',\n",
       " 'alfajores around',\n",
       " 'alfajores received',\n",
       " 'alfalfa',\n",
       " 'alfalfa 100mg',\n",
       " 'alfalfa 285',\n",
       " 'alfalfa all',\n",
       " 'alfalfa alone',\n",
       " 'alfalfa and',\n",
       " 'alfalfa as',\n",
       " 'alfalfa barley',\n",
       " 'alfalfa beef',\n",
       " 'alfalfa br',\n",
       " 'alfalfa but',\n",
       " 'alfalfa cabbage',\n",
       " 'alfalfa calcium',\n",
       " 'alfalfa canavanine',\n",
       " 'alfalfa clover',\n",
       " 'alfalfa controvercial',\n",
       " 'alfalfa cubes',\n",
       " 'alfalfa dried',\n",
       " 'alfalfa extract',\n",
       " 'alfalfa feed',\n",
       " 'alfalfa fenugreek',\n",
       " 'alfalfa flavor',\n",
       " 'alfalfa flax',\n",
       " 'alfalfa flaxseed',\n",
       " 'alfalfa for',\n",
       " 'alfalfa fro',\n",
       " 'alfalfa grass',\n",
       " 'alfalfa green',\n",
       " 'alfalfa had',\n",
       " 'alfalfa has',\n",
       " 'alfalfa hay',\n",
       " 'alfalfa in',\n",
       " 'alfalfa into',\n",
       " 'alfalfa is',\n",
       " 'alfalfa it',\n",
       " 'alfalfa leaf',\n",
       " 'alfalfa leaves',\n",
       " 'alfalfa like',\n",
       " 'alfalfa meal',\n",
       " 'alfalfa minerals',\n",
       " 'alfalfa mustard',\n",
       " 'alfalfa not',\n",
       " 'alfalfa nutrient',\n",
       " 'alfalfa on',\n",
       " 'alfalfa once',\n",
       " 'alfalfa or',\n",
       " 'alfalfa organic',\n",
       " 'alfalfa peas',\n",
       " 'alfalfa pellet',\n",
       " 'alfalfa perhaps',\n",
       " 'alfalfa potatoes',\n",
       " 'alfalfa put',\n",
       " 'alfalfa radish',\n",
       " 'alfalfa resembling',\n",
       " 'alfalfa rose',\n",
       " 'alfalfa seed',\n",
       " 'alfalfa seeds',\n",
       " 'alfalfa smells',\n",
       " 'alfalfa so',\n",
       " 'alfalfa spirulina',\n",
       " 'alfalfa splash',\n",
       " 'alfalfa sprout',\n",
       " 'alfalfa sprouting',\n",
       " 'alfalfa sprouts',\n",
       " 'alfalfa tablets',\n",
       " 'alfalfa tastes',\n",
       " 'alfalfa tea',\n",
       " 'alfalfa that',\n",
       " 'alfalfa the',\n",
       " 'alfalfa there',\n",
       " 'alfalfa they',\n",
       " 'alfalfa to',\n",
       " 'alfalfa too',\n",
       " 'alfalfa treacle',\n",
       " 'alfalfa turns',\n",
       " 'alfalfa until',\n",
       " 'alfalfa use',\n",
       " 'alfalfa wafts',\n",
       " 'alfalfa was',\n",
       " 'alfalfa which',\n",
       " 'alfalfa will',\n",
       " 'alfalfa wouldn',\n",
       " 'alfalfa you',\n",
       " 'alfalfas',\n",
       " 'alfalfas and',\n",
       " 'alfalfas grocery',\n",
       " 'alfalpha',\n",
       " 'alfalpha tablets',\n",
       " 'alfie',\n",
       " 'alfie just',\n",
       " 'alfonso',\n",
       " 'alfonso olive',\n",
       " 'alford',\n",
       " 'alford oats',\n",
       " 'alford organic',\n",
       " 'alford stonecut',\n",
       " 'alfrado',\n",
       " 'alfrado sause',\n",
       " 'alfred',\n",
       " 'alfred hitchcock',\n",
       " 'alfred neuman',\n",
       " 'alfred vogel',\n",
       " 'alfreda',\n",
       " 'alfreda sauce',\n",
       " 'alfredo',\n",
       " 'alfredo 12',\n",
       " 'alfredo adding',\n",
       " 'alfredo afraid',\n",
       " 'alfredo again',\n",
       " 'alfredo am',\n",
       " 'alfredo and',\n",
       " 'alfredo at',\n",
       " 'alfredo because',\n",
       " 'alfredo box',\n",
       " 'alfredo br',\n",
       " 'alfredo broccoli',\n",
       " 'alfredo but',\n",
       " 'alfredo cheese',\n",
       " 'alfredo clams',\n",
       " 'alfredo dinner',\n",
       " 'alfredo dish',\n",
       " 'alfredo dishes',\n",
       " 'alfredo don',\n",
       " 'alfredo esque',\n",
       " 'alfredo etc',\n",
       " 'alfredo even',\n",
       " 'alfredo ever',\n",
       " 'alfredo filling',\n",
       " 'alfredo flavor',\n",
       " 'alfredo for',\n",
       " 'alfredo has',\n",
       " 'alfredo have',\n",
       " 'alfredo here',\n",
       " 'alfredo his',\n",
       " 'alfredo impress',\n",
       " 'alfredo in',\n",
       " 'alfredo interesting',\n",
       " 'alfredo is',\n",
       " 'alfredo it',\n",
       " 'alfredo just',\n",
       " 'alfredo lasagna',\n",
       " 'alfredo like',\n",
       " 'alfredo love',\n",
       " 'alfredo low',\n",
       " 'alfredo made',\n",
       " 'alfredo mix',\n",
       " 'alfredo mixes',\n",
       " 'alfredo noodles',\n",
       " 'alfredo on',\n",
       " 'alfredo or',\n",
       " 'alfredo out',\n",
       " 'alfredo packets',\n",
       " 'alfredo pasta',\n",
       " 'alfredo peanut',\n",
       " 'alfredo person',\n",
       " 'alfredo probably',\n",
       " 'alfredo quite',\n",
       " 'alfredo really',\n",
       " 'alfredo recipie',\n",
       " 'alfredo sauce',\n",
       " 'alfredo sauces',\n",
       " 'alfredo sause',\n",
       " 'alfredo she',\n",
       " 'alfredo so',\n",
       " 'alfredo style',\n",
       " 'alfredo than',\n",
       " 'alfredo that',\n",
       " 'alfredo the',\n",
       " 'alfredo there',\n",
       " 'alfredo this',\n",
       " 'alfredo to',\n",
       " 'alfredo tomato',\n",
       " 'alfredo using',\n",
       " 'alfredo variety',\n",
       " 'alfredo ve',\n",
       " 'alfredo version',\n",
       " 'alfredo versions',\n",
       " 'alfredo well',\n",
       " 'alfredo while',\n",
       " 'alfredo with',\n",
       " 'alfredo you',\n",
       " 'alfredo yum',\n",
       " 'alfredos',\n",
       " 'alfredos and',\n",
       " 'alfresco',\n",
       " 'alfresco on',\n",
       " 'alfully',\n",
       " 'alfully funny',\n",
       " 'algae',\n",
       " 'algae algae',\n",
       " 'algae all',\n",
       " 'algae and',\n",
       " 'algae are',\n",
       " 'algae as',\n",
       " 'algae based',\n",
       " 'algae because',\n",
       " 'algae bloom',\n",
       " 'algae caps',\n",
       " 'algae contain',\n",
       " 'algae eater',\n",
       " 'algae eaters',\n",
       " 'algae eating',\n",
       " 'algae echinacea',\n",
       " 'algae etc',\n",
       " 'algae flakes',\n",
       " 'algae for',\n",
       " 'algae from',\n",
       " 'algae growing',\n",
       " 'algae has',\n",
       " 'algae is',\n",
       " 'algae kinds',\n",
       " 'algae meal',\n",
       " 'algae organic',\n",
       " 'algae shakes',\n",
       " 'algae shame',\n",
       " 'algae sheets',\n",
       " 'algae some',\n",
       " 'algae sources',\n",
       " 'algae spinach',\n",
       " 'algae tablet',\n",
       " 'algae that',\n",
       " 'algae using',\n",
       " 'algae vcaps',\n",
       " 'algae veggie',\n",
       " 'algae weirdly',\n",
       " 'algaecide',\n",
       " 'algaecide the',\n",
       " 'algaes',\n",
       " 'algaes added',\n",
       " 'algal',\n",
       " 'algal bloom',\n",
       " 'algal oil',\n",
       " 'algal scum',\n",
       " 'algal toxins',\n",
       " 'algam',\n",
       " 'algam is',\n",
       " 'algam literally',\n",
       " 'algarroba',\n",
       " 'algarroba locust',\n",
       " 'algarve',\n",
       " 'algarve guia',\n",
       " 'algarve region',\n",
       " 'algave',\n",
       " 'algave products',\n",
       " 'alge',\n",
       " 'alge have',\n",
       " 'algea',\n",
       " 'algea and',\n",
       " 'algea as',\n",
       " 'algea growing',\n",
       " 'algea killer',\n",
       " 'algeas',\n",
       " 'algeas close',\n",
       " 'algeas then',\n",
       " 'algebra',\n",
       " 'algebra of',\n",
       " 'algedonic',\n",
       " 'algedonic experience',\n",
       " 'alger1',\n",
       " 'algeria',\n",
       " 'algeria and',\n",
       " 'algeria deglet',\n",
       " 'algeria it',\n",
       " 'algeria morocco',\n",
       " 'algerian',\n",
       " 'algerian couscous',\n",
       " 'algerian desert',\n",
       " 'algerian lamb',\n",
       " 'algerian or',\n",
       " 'algerian restaurant',\n",
       " 'algernon',\n",
       " 'algernon freeman',\n",
       " 'algernon mitford',\n",
       " 'algin',\n",
       " 'algin br',\n",
       " 'algin sodium',\n",
       " 'alginate',\n",
       " 'alginate and',\n",
       " 'alginate binds',\n",
       " 'alginate bought',\n",
       " 'alginate br',\n",
       " 'alginate caramel',\n",
       " 'alginate corn',\n",
       " 'alginate guar',\n",
       " 'alginate highly',\n",
       " 'alginate in',\n",
       " 'alginate is',\n",
       " 'alginate locust',\n",
       " 'alginate red',\n",
       " 'alginate sorbic',\n",
       " 'alginate sorbitan',\n",
       " 'alginate soy',\n",
       " 'alginate spices',\n",
       " 'alginate xantham',\n",
       " 'alginate xanthan',\n",
       " 'alginates',\n",
       " 'alginates seems',\n",
       " 'algo',\n",
       " 'algo que',\n",
       " 'algo tan',\n",
       " 'algo vegetal',\n",
       " 'algodones',\n",
       " 'algodones bought',\n",
       " 'algorithm',\n",
       " 'algorithm if',\n",
       " 'algorithm knew',\n",
       " 'algorithm this',\n",
       " 'algorithms',\n",
       " 'algorithms have',\n",
       " 'algorythm',\n",
       " 'algorythm anymore',\n",
       " 'alguien',\n",
       " 'alguien me',\n",
       " 'alguien que',\n",
       " 'algunos',\n",
       " 'algunos se',\n",
       " 'alheimers',\n",
       " 'alheimers patients',\n",
       " 'ali',\n",
       " 'ali ginseng',\n",
       " 'ali in',\n",
       " 'ali is',\n",
       " 'ali julia',\n",
       " 'ali shan',\n",
       " 'ali tastes',\n",
       " 'ali which',\n",
       " 'ali with',\n",
       " 'alia',\n",
       " 'alia as',\n",
       " 'alia magnesium',\n",
       " 'alias',\n",
       " 'alias 3dgrocery',\n",
       " 'alias did',\n",
       " 'alias kafe',\n",
       " 'alias kape',\n",
       " 'alias names',\n",
       " 'aliases',\n",
       " 'aliases labeling',\n",
       " 'aliases msg',\n",
       " 'aliases this',\n",
       " 'alicante',\n",
       " 'alicante 200',\n",
       " 'alicante and',\n",
       " 'alice',\n",
       " 'alice ben',\n",
       " 'alice com',\n",
       " 'alice delaney',\n",
       " 'alice in',\n",
       " 'alice jeanne',\n",
       " 'alice la',\n",
       " 'alice lichtenstein',\n",
       " 'alice medrich',\n",
       " 'alice miller',\n",
       " 'alice shared',\n",
       " 'alice theme',\n",
       " 'alice waters',\n",
       " 'alicia',\n",
       " 'alicia electric',\n",
       " 'alicia or',\n",
       " 'alicia silverstone',\n",
       " 'alicia silverstones',\n",
       " 'alicious',\n",
       " 'alien',\n",
       " 'alien and',\n",
       " 'alien artifact',\n",
       " 'alien asian',\n",
       " 'alien blob',\n",
       " 'alien blood',\n",
       " 'alien corpse',\n",
       " 'alien cpap',\n",
       " 'alien eyes',\n",
       " 'alien finger',\n",
       " 'alien goo',\n",
       " 'alien in',\n",
       " 'alien it',\n",
       " 'alien life',\n",
       " 'alien love',\n",
       " 'alien mud',\n",
       " 'alien nation',\n",
       " 'alien noodle',\n",
       " 'alien on',\n",
       " 'alien overlords',\n",
       " 'alien party',\n",
       " 'alien rubbery',\n",
       " 'alien snack',\n",
       " 'alien space',\n",
       " 'alien species',\n",
       " 'alien sticker',\n",
       " 'alien style',\n",
       " 'alien technology',\n",
       " 'alien thought',\n",
       " 'alien to',\n",
       " 'alien treats',\n",
       " 'alien version',\n",
       " 'alien would',\n",
       " 'alienated',\n",
       " 'alienated from',\n",
       " 'alienating',\n",
       " 'alienating him',\n",
       " 'alienation',\n",
       " 'alienation of',\n",
       " 'aliens',\n",
       " 'aliens attack',\n",
       " 'aliens from',\n",
       " 'aliens may',\n",
       " 'aliens movie',\n",
       " 'aliens were',\n",
       " 'aliens who',\n",
       " 'aliens will',\n",
       " 'aliento',\n",
       " 'aliento fresco',\n",
       " 'alieve',\n",
       " 'alieve everyday',\n",
       " 'alieves',\n",
       " 'alieves 220mg',\n",
       " 'aligator',\n",
       " 'aligator had',\n",
       " 'aligator print',\n",
       " 'aligator than',\n",
       " 'aligator that',\n",
       " 'aligator the',\n",
       " 'alight',\n",
       " 'alight upon',\n",
       " 'align',\n",
       " 'align and',\n",
       " 'align basket',\n",
       " 'align itself',\n",
       " 'align lid',\n",
       " 'align probiatic',\n",
       " 'align the',\n",
       " 'align well',\n",
       " 'align with',\n",
       " 'aligned',\n",
       " 'aligned it',\n",
       " 'aligned itself',\n",
       " 'aligned just',\n",
       " 'aligned to',\n",
       " 'aligned with',\n",
       " 'aligning',\n",
       " 'aligning the',\n",
       " 'aligning with',\n",
       " 'alignment',\n",
       " 'alignment at',\n",
       " 'alignment br',\n",
       " 'alignment none',\n",
       " 'alignment with',\n",
       " 'aligns',\n",
       " 'aligns and',\n",
       " 'aligns well',\n",
       " 'alii',\n",
       " 'alii drive',\n",
       " 'aliitle',\n",
       " 'aliitle skeptical',\n",
       " 'alike',\n",
       " 'alike added',\n",
       " 'alike all',\n",
       " 'alike also',\n",
       " 'alike am',\n",
       " 'alike amazing',\n",
       " 'alike and',\n",
       " 'alike are',\n",
       " 'alike as',\n",
       " 'alike at',\n",
       " 'alike bear',\n",
       " 'alike best',\n",
       " 'alike blocks',\n",
       " 'alike blue',\n",
       " 'alike boy',\n",
       " 'alike br',\n",
       " 'alike btw',\n",
       " 'alike but',\n",
       " 'alike buy',\n",
       " 'alike can',\n",
       " 'alike chewing',\n",
       " 'alike children',\n",
       " 'alike corporate',\n",
       " 'alike don',\n",
       " 'alike east',\n",
       " 'alike eat',\n",
       " 'alike enjoy',\n",
       " 'alike enjoyed',\n",
       " 'alike especially',\n",
       " 'alike every',\n",
       " 'alike everyone',\n",
       " 'alike except',\n",
       " 'alike find',\n",
       " 'alike found',\n",
       " 'alike from',\n",
       " 'alike got',\n",
       " 'alike great',\n",
       " 'alike happily',\n",
       " 'alike happy',\n",
       " 'alike have',\n",
       " 'alike highly',\n",
       " 'alike however',\n",
       " 'alike if',\n",
       " 'alike in',\n",
       " 'alike is',\n",
       " 'alike it',\n",
       " 'alike its',\n",
       " 'alike just',\n",
       " 'alike keep',\n",
       " 'alike kids',\n",
       " 'alike know',\n",
       " 'alike label',\n",
       " 'alike like',\n",
       " 'alike love',\n",
       " 'alike lower',\n",
       " 'alike luckily',\n",
       " 'alike more',\n",
       " 'alike must',\n",
       " 'alike mw',\n",
       " 'alike my',\n",
       " 'alike no',\n",
       " 'alike not',\n",
       " 'alike note',\n",
       " 'alike now',\n",
       " 'alike often',\n",
       " 'alike on',\n",
       " 'alike other',\n",
       " 'alike personally',\n",
       " 'alike products',\n",
       " 'alike really',\n",
       " 'alike recommend',\n",
       " 'alike replacement',\n",
       " 'alike rich',\n",
       " 'alike right',\n",
       " 'alike roland',\n",
       " 'alike see',\n",
       " 'alike should',\n",
       " 'alike so',\n",
       " 'alike someone',\n",
       " 'alike sooooooooooo',\n",
       " 'alike stuff',\n",
       " 'alike thank',\n",
       " 'alike thanks',\n",
       " 'alike that',\n",
       " 'alike the',\n",
       " 'alike these',\n",
       " 'alike they',\n",
       " 'alike think',\n",
       " 'alike this',\n",
       " 'alike thumbs',\n",
       " 'alike to',\n",
       " 'alike told',\n",
       " 'alike try',\n",
       " 'alike tully',\n",
       " 'alike until',\n",
       " 'alike use',\n",
       " 'alike ve',\n",
       " 'alike very',\n",
       " 'alike was',\n",
       " 'alike we',\n",
       " 'alike what',\n",
       " 'alike when',\n",
       " 'alike where',\n",
       " 'alike which',\n",
       " 'alike why',\n",
       " 'alike will',\n",
       " 'alike win',\n",
       " 'alike with',\n",
       " 'alike within',\n",
       " 'alike would',\n",
       " 'alike you',\n",
       " 'alike yum',\n",
       " 'alikes',\n",
       " 'alikes had',\n",
       " 'alikes on',\n",
       " 'alikes that',\n",
       " 'alimenta',\n",
       " 'alimenta de',\n",
       " 'alimentari',\n",
       " 'alimentari all',\n",
       " 'alimentari basil',\n",
       " 'alimentari has',\n",
       " 'alimentari is',\n",
       " 'alimentari it',\n",
       " 'alimentari products',\n",
       " 'alimentari provided',\n",
       " 'alimentari tuscan',\n",
       " 'alimentary',\n",
       " 'alimentary paste',\n",
       " 'alimentium',\n",
       " 'alimentium is',\n",
       " 'alimento',\n",
       " 'alimento un',\n",
       " 'aliments',\n",
       " 'aliments and',\n",
       " 'aliments especially',\n",
       " 'aliments harding',\n",
       " 'aliments the',\n",
       " 'aliments will',\n",
       " 'alimentum',\n",
       " 'alimentum 24',\n",
       " 'alimentum also',\n",
       " 'alimentum and',\n",
       " 'alimentum as',\n",
       " 'alimentum baby',\n",
       " 'alimentum because',\n",
       " 'alimentum before',\n",
       " 'alimentum br',\n",
       " 'alimentum but',\n",
       " 'alimentum by',\n",
       " 'alimentum contain',\n",
       " 'alimentum does',\n",
       " 'alimentum due',\n",
       " 'alimentum every',\n",
       " 'alimentum for',\n",
       " 'alimentum formula',\n",
       " 'alimentum from',\n",
       " 'alimentum have',\n",
       " 'alimentum hypoallergenic',\n",
       " 'alimentum instead',\n",
       " 'alimentum is',\n",
       " 'alimentum it',\n",
       " 'alimentum my',\n",
       " 'alimentum nearing',\n",
       " 'alimentum nutramigen',\n",
       " 'alimentum nutrilon',\n",
       " 'alimentum powder',\n",
       " 'alimentum predigested',\n",
       " 'alimentum ready',\n",
       " 'alimentum really',\n",
       " 'alimentum rtf',\n",
       " 'alimentum she',\n",
       " 'alimentum since',\n",
       " 'alimentum so',\n",
       " 'alimentum started',\n",
       " 'alimentum tastes',\n",
       " 'alimentum the',\n",
       " 'alimentum there',\n",
       " 'alimentum to',\n",
       " 'alimentum was',\n",
       " 'alimentum we',\n",
       " 'alimentum when',\n",
       " 'alimentum which',\n",
       " 'alimnuntem',\n",
       " 'alimnuntem it',\n",
       " 'alimony',\n",
       " 'alimony can',\n",
       " 'alimony in',\n",
       " 'alimony payments',\n",
       " 'alio',\n",
       " 'alio alio',\n",
       " 'alio confirming',\n",
       " 'alio review',\n",
       " 'aliqoute',\n",
       " 'aliqoute the',\n",
       " 'aliquot',\n",
       " 'aliquot of',\n",
       " 'aliso',\n",
       " 'aliso viejo',\n",
       " 'alison',\n",
       " 'alison and',\n",
       " 'alissi',\n",
       " 'alissi porcini',\n",
       " 'alitas',\n",
       " 'alitas de',\n",
       " 'alittle',\n",
       " 'alittle banged',\n",
       " 'alittle beforehand',\n",
       " 'alittle better',\n",
       " 'alittle bit',\n",
       " 'alittle bitter',\n",
       " 'alittle bold',\n",
       " 'alittle cash',\n",
       " 'alittle cinnamon',\n",
       " 'alittle clumpy',\n",
       " 'alittle color',\n",
       " 'alittle comfusing',\n",
       " 'alittle cream',\n",
       " 'alittle different',\n",
       " 'alittle dry',\n",
       " 'alittle equal',\n",
       " 'alittle expensive',\n",
       " 'alittle extra',\n",
       " 'alittle flat',\n",
       " 'alittle get',\n",
       " 'alittle getting',\n",
       " 'alittle goat',\n",
       " 'alittle goes',\n",
       " 'alittle grainy',\n",
       " 'alittle granola',\n",
       " 'alittle hard',\n",
       " 'alittle heavier',\n",
       " 'alittle help',\n",
       " 'alittle hesitant',\n",
       " 'alittle higher',\n",
       " 'alittle hooked',\n",
       " 'alittle hot',\n",
       " 'alittle improvement',\n",
       " 'alittle kick',\n",
       " 'alittle lemon',\n",
       " 'alittle less',\n",
       " 'alittle light',\n",
       " 'alittle lighter',\n",
       " 'alittle like',\n",
       " 'alittle longer',\n",
       " 'alittle margarine',\n",
       " 'alittle milder',\n",
       " 'alittle money',\n",
       " 'alittle more',\n",
       " 'alittle morning',\n",
       " 'alittle neem',\n",
       " 'alittle of',\n",
       " 'alittle on',\n",
       " 'alittle over',\n",
       " 'alittle overweight',\n",
       " 'alittle plain',\n",
       " 'alittle pricey',\n",
       " 'alittle pricy',\n",
       " 'alittle rancid',\n",
       " 'alittle real',\n",
       " 'alittle reluctant',\n",
       " 'alittle rice',\n",
       " 'alittle rubbery',\n",
       " 'alittle scuffed',\n",
       " 'alittle sea',\n",
       " 'alittle searching',\n",
       " 'alittle skeptical',\n",
       " 'alittle smaller',\n",
       " 'alittle smoother',\n",
       " 'alittle softer',\n",
       " 'alittle spicy',\n",
       " 'alittle squirt',\n",
       " 'alittle stale',\n",
       " 'alittle sticky',\n",
       " 'alittle stiffer',\n",
       " 'alittle strong',\n",
       " 'alittle sweet',\n",
       " 'alittle sweeter',\n",
       " 'alittle taco',\n",
       " 'alittle tart',\n",
       " 'alittle tin',\n",
       " 'alittle to',\n",
       " 'alittle too',\n",
       " 'alittle unsure',\n",
       " 'alittle vinegary',\n",
       " 'alittle warm',\n",
       " 'alittle wary',\n",
       " 'alittle weak',\n",
       " 'alittle weaker',\n",
       " 'alittle weird',\n",
       " 'alittle whimsy',\n",
       " 'alittle with',\n",
       " 'alittle worried',\n",
       " 'alittle would',\n",
       " 'alive',\n",
       " 'alive 44',\n",
       " 'alive 70',\n",
       " 'alive after',\n",
       " 'alive again',\n",
       " 'alive alive',\n",
       " 'alive all',\n",
       " 'alive also',\n",
       " 'alive although',\n",
       " 'alive am',\n",
       " 'alive and',\n",
       " 'alive animal',\n",
       " 'alive any',\n",
       " 'alive are',\n",
       " 'alive as',\n",
       " 'alive at',\n",
       " 'alive awake',\n",
       " 'alive before',\n",
       " 'alive bought',\n",
       " 'alive br',\n",
       " 'alive bubbly',\n",
       " 'alive but',\n",
       " 'alive by',\n",
       " 'alive came',\n",
       " 'alive can',\n",
       " 'alive carefully',\n",
       " 'alive chia',\n",
       " 'alive considering',\n",
       " 'alive demands',\n",
       " 'alive don',\n",
       " 'alive drop',\n",
       " 'alive etc',\n",
       " 'alive even',\n",
       " 'alive every',\n",
       " 'alive fast',\n",
       " 'alive feeling',\n",
       " 'alive female',\n",
       " 'alive find',\n",
       " 'alive first',\n",
       " 'alive flax',\n",
       " 'alive flopping',\n",
       " 'alive for',\n",
       " 'alive from',\n",
       " 'alive garlic',\n",
       " 'alive get',\n",
       " 'alive give',\n",
       " 'alive golden',\n",
       " 'alive got',\n",
       " 'alive great',\n",
       " 'alive grew',\n",
       " 'alive had',\n",
       " 'alive has',\n",
       " 'alive have',\n",
       " 'alive he',\n",
       " 'alive healthy',\n",
       " 'alive heat',\n",
       " 'alive his',\n",
       " 'alive hope',\n",
       " 'alive hot',\n",
       " 'alive if',\n",
       " 'alive imagine',\n",
       " 'alive in',\n",
       " 'alive including',\n",
       " 'alive indoors',\n",
       " 'alive instead',\n",
       " 'alive is',\n",
       " 'alive it',\n",
       " 'alive just',\n",
       " 'alive keep',\n",
       " 'alive knowledge',\n",
       " 'alive leave',\n",
       " 'alive let',\n",
       " 'alive like',\n",
       " 'alive liquid',\n",
       " 'alive ll',\n",
       " 'alive lol',\n",
       " 'alive long',\n",
       " 'alive longer',\n",
       " 'alive maine',\n",
       " 'alive makes',\n",
       " 'alive must',\n",
       " 'alive my',\n",
       " 'alive nice',\n",
       " 'alive now',\n",
       " 'alive on',\n",
       " 'alive once',\n",
       " 'alive or',\n",
       " 'alive organic',\n",
       " 'alive pleasant',\n",
       " 'alive pretty',\n",
       " 'alive pure',\n",
       " 'alive radiant',\n",
       " 'alive red',\n",
       " 'alive rescue',\n",
       " 'alive seriously',\n",
       " 'alive she',\n",
       " 'alive significant',\n",
       " 'alive snatched',\n",
       " 'alive so',\n",
       " 'alive stars',\n",
       " 'alive still',\n",
       " 'alive taste',\n",
       " 'alive than',\n",
       " 'alive thank',\n",
       " ...]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuers[100000:1000010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(final_tf_idf[3,:].toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "763fe82668c745b71dc1a42b603db56da0adb11fff41a059c08289bf1729dbe0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
